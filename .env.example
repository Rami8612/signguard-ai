# ═══════════════════════════════════════════════════════════════
# SignGuard AI - Environment Configuration
# ═══════════════════════════════════════════════════════════════
# Copy this file to .env and fill in your values
# cp .env.example .env

# ───────────────────────────────────────────────────────────────
# Server Configuration
# ───────────────────────────────────────────────────────────────

# API server port (default: 3001)
PORT=3001

# ───────────────────────────────────────────────────────────────
# AI Provider API Keys
# ───────────────────────────────────────────────────────────────
# Configure at least one provider for AI-powered explanations.
# The system will use the first available provider in this order:
# Gemini (default) > OpenRouter > Claude > OpenAI > Ollama (local)

# ⭐ Google Gemini - DEFAULT AND RECOMMENDED
# Fast, accurate, and cost-effective. Uses Gemini 3 Flash by default.
# Get your FREE key at: https://aistudio.google.com/app/apikey
IA_GEMINI_API_KEY=

# OpenRouter - Access multiple AI models through one API
# Get your key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# Anthropic Claude - Direct access to Claude models
# Get your key at: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# OpenAI - GPT models
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Ollama - Local AI models (no API key required)
# Install Ollama: https://ollama.ai
# Default URL if not specified: http://localhost:11434
OLLAMA_URL=http://localhost:11434

# ───────────────────────────────────────────────────────────────
# Frontend Configuration (Vite)
# ───────────────────────────────────────────────────────────────
# These variables must be prefixed with VITE_ to be exposed to the frontend

# Backend API URL (for production deployments)
# In development, the Vite proxy handles this automatically
# VITE_API_URL=http://localhost:3001
